## 6\. Agent System (LangGraph Architecture)

Our system employs a collection of specialized agents – think of them as microservices or autonomous bots (some purely rule-based, others leveraging AI/LLM reasoning) – that operate on the unified graph. Each agent has a well-defined role with specific responsibilities and tools. Crucially, every action an agent performs is recorded in the Provenance ontology of the graph as an auditable event (modeled as :Action nodes grouped by :Commit nodes). This LangGraph agent layer enables intelligent automation (e.g. content extraction, document generation, compliance checks) by allowing agents to query and update the Neo4j graph (often via Cypher) in a controlled manner ￼ ￼. All agent operations happen within constrained, reviewable bounds – no “black-box” magic. In implementation, the agents are realized across our services: for example, the Sync Worker service acts as a File Steward agent for ingestion, while the LangGraph service hosts AI-driven agents for reasoning and document synthesis ￼ ￼. The Orchestrator API coordinates these interactions, routing tasks to the appropriate agent service (via direct HTTP calls or internal queues) and ensuring results are persisted ￼.

### 6.1 Key Agents and Their Roles

#### File Steward Agent

Role & Responsibilities: The File Steward is essentially the librarian of the system, keeping the File Ontology in sync with external storage and mapping files into the canonical structure. It monitors incoming file events (from Dropbox, Google Drive, etc.) and runs the ingestion pipeline (see Section 2\) to integrate each file into the graph. When a new file or folder is created/updated in the external source, the File Steward captures an event (via our Supabase outbox triggers) and ensures the Neo4j graph is updated accordingly. Concretely, this involves creating or updating the corresponding :File node with its metadata, linking it to its parent :Folder and to the relevant :Project node ￼ ￼. For example, on receiving an "INSERT" event for a file, the agent (running in the Sync Worker) will upsert a File node with properties like name, path, size, MIME type, timestamps, etc., identified by a stable UUID ￼ ￼. It then establishes relationships such as (:Folder)-\[:CONTAINS\]-\>(:File) and (:Project)-\[:HAS\_FILE\]-\>(:File) so the file is situated in the graph's hierarchy ￼ ￼.

**TELEMETRY:** The File Steward emits comprehensive agent job metrics: `olivine_agent_jobs_total{agent="file_steward", job_type}` counts started jobs, `olivine_agent_jobs_failed_total{agent="file_steward", job_type}` tracks failures, and `olivine_actions_failed_total{tool}` monitors individual action failures with tool-specific labels for classification, linking, and slot assignment operations. The File Steward also classifies files into canonical slots (standard categories like SCRIPT\_PRIMARY, BUDGET\_FINAL, CALLSHEET\_DRAFT, etc.) using a combination of pattern rules and ML. This classification is how the system “knows” what role a file plays in the production. Currently, basic folder-based classification is implemented (e.g. linking file to a project by folder) but full slot tagging is a GAP – CanonicalSlot nodes are planned but not yet present in the schema ￼. FIX: Ingest logic will be extended to assign a slot label or create a :CanonicalSlot node and link File to it once the taxonomy is defined. We anticipate maintaining a set of :TaxonomyRule (another not-yet-implemented node type) encoding patterns (filename regex, folder path rules, etc.) to auto-tag files ￼. The File Steward agent would apply these rules on each new file (and could even invoke an ML model for fuzzy matching when rules are not confident), then attach the file to the appropriate slot via a (:File)-\[:FILLS\_SLOT\]-\>(:CanonicalSlot) relationship. If an encountered file doesn’t match any known pattern with high confidence, the agent can propose a new taxonomy rule: it would create a :TypeDefProposal node suggesting a new slot or category for that file (for review by the Ontology Curator) ￼. All these ingestion steps happen automatically and asynchronously. Internally, the Sync Worker polls the sync\_events outbox table (Supabase) for new file events and processes them in batches ￼ ￼. Each processed event is marked completed in the outbox and the changes are written to Neo4j within a single transaction. Author attribution: File Steward commits are attributed to a system identity (e.g. "sync\_worker" or an agent ID) to distinguish automated changes from user edits ￼ ￼.

#### Ontology Curator Agent

Role & Responsibilities: The Ontology Curator acts as the governance mechanism for the evolving schema (the ontologies). When the system or a user proposes a new entity type, relationship type, or enumeration value (captured as a :TypeDefProposal node in the graph), this agent reviews the proposal and decides how to proceed. For instance, if an agent or user suggests a new crew role “RiggingTeam” that doesn’t exist in the current schema, a TypeDefProposal(label="RiggingTeam", ...) node would be created with metadata about the proposal ￼. The Curator wakes up to evaluate such proposals. It checks for duplication (perhaps we already have “RiggingCrew” as a role), ensures required properties or constraints are mentioned, and assesses if the proposal aligns with our modeling principles. Straightforward cases are auto-approved: e.g. adding a new allowed value to an enum list (like a new CrewRole) can be done automatically by updating the reference data in the Postgres DB or an internal enum definition. More complex proposals – such as introducing an entirely new node label or relationship type – might require human confirmation. The Ontology Curator can leverage an LLM to parse the human-readable rationale attached to the proposal and compare it against the existing ontology. If the rationale is convincing and no conflicts are detected, the agent can auto-approve and commit the new type definition (for example, it might create a new Neo4j constraint or update an introspection schema). If there’s ambiguity (say the proposal might duplicate an existing concept), it flags the proposal for human review, possibly by creating an alert or task in the system. Implementation: Currently, this agent’s logic is not implemented (GAP) – proposals can be created, but no automated curator process runs. FIX: We will implement the Curator as a background process (likely as part of the LangGraph orchestrator service) that listens for new TypeDefProposal nodes or a corresponding Supabase event. On detection, it will fetch the proposal details (e.g. proposed label, proposed properties, rationale text) and compare against the current schema. This could involve querying Neo4j schema data (labels, relationship types, constraints) and perhaps a predefined policy file (for disallowed patterns, naming conventions, etc.). We plan to integrate an LLM via a tool call like llm.evaluate\_proposal to read the rationale and summarize any issues. For auditability, the Curator’s decision (auto-approve, modify, or escalate) will itself be recorded as a commit with an Action like tool="ontology.curator" and the outcome noted (approved/rejected with reason). If approved, the agent would apply the change, e.g. create the new enum node or update a config, then mark the proposal node as resolved (perhaps linking it with an APPROVED relationship to the new schema element). In the meantime, any unhandled proposals would simply remain in the graph for an administrator to manually review. This ensures that the schema can evolve, but in a controlled, traceable way – no rogue types enter without oversight ￼.

#### Composer Agents (Document Generators)

Role & Responsibilities: Composer agents are responsible for generating aggregate documents or outputs (PDFs, reports, schedules) by pulling data from the graph and formatting it. We anticipate multiple specialized composers: e.g. a Call Sheet Composer, Budget Report Composer, Shooting Schedule Composer, etc. Taking the Call Sheet Composer as a representative example: this agent assembles the daily call sheet – a multi-section document listing the scenes to shoot, cast and crew call times, locations, weather, etc. The agent's job is to gather all relevant info from both the Content and Ops ontologies and produce a formatted call sheet file, which is then fed back into the File ontology. Implementation-wise, the Composer agent operates as a workflow: it first queries the Neo4j graph for the needed data for a given shooting day, then uses either a template or an LLM to generate the document content, and finally writes out the file and updates the graph. We ensure that the agent's inputs (data it read) and outputs (file generated, any graph updates) are fully traceable via a commit (see Provenance below).

**TELEMETRY:** Composer agents emit detailed job metrics: `olivine_agent_jobs_total{agent="composer", job_type="callsheet|budget|schedule"}` tracks generation jobs, `olivine_agent_jobs_failed_total{agent="composer", job_type}` monitors failures, and `olivine_actions_failed_total{tool="composer.callsheet|llm.call.openai|pdf.fill"}` provides granular tool-level failure tracking for document assembly, LLM calls, and PDF generation operations.

Data Gathering: The agent uses Cypher queries to retrieve structured data. For example, to build a call sheet for 2025-08-09, it would query for the ShootDay node for that date and pull all connected Scenes, along with their Locations, required Props, scheduled Crew, etc. ￼ ￼. This may involve multiple queries or traversals. The result is a consolidated in-memory dataset (scenes list, cast list, location details, etc.). The agent ensures that all prerequisites are present – e.g. that the graph actually has a Template for call sheets, up-to-date crew info, and so on ￼ ￼. If anything is missing or inconsistent (say a scene has no location set, or no template exists), the agent will log an error or raise a notification instead of producing a flawed document. (In a future iteration, the agent might even attempt to auto-resolve certain issues – for instance, if a schedule is missing a scene’s location, it could look in the File ontology for a document that might contain that info.)

External Tools: Before composing the document, the agent may call external APIs to enrich the data. A common example is fetching the weather forecast for the shooting location and date, which many film crews include on call sheets. The Call Sheet Composer has access to a “weather fetch” tool (integrated via an API client, e.g., OpenWeatherMap). It will supply the location (from the ShootDay or Location node, which might have coordinates or city name) and date, and get back forecast data (e.g. “Cloudy, high 75°F”). This API call is logged as an Action with tool name "weather.api" (or similar) and its inputs (location/date) and outputs (the returned weather info) recorded ￼. The agent might attach the fetched weather summary to the ShootDay node as a property or just hold it in memory for the document. Other tools a composer might use include PDF generators or document template engines. For instance, if call sheets are based on a PDF form, the agent could use a PDF form-filling library (tool "pdf.fill"). If using an LLM to format the call sheet in natural language, the agent could have a prompt template and call an OpenAI model (tool "llm.call.openai") to produce nicely formatted text for the call sheet sections. These tool invocations are all encapsulated as Actions in the provenance log.

{{ ... }}

Traceability: The Composer agent’s entire run is encapsulated in a commit. When it finishes, it creates a new :Commit node (with properties like message \= "Generated Call Sheet for 2025-08-09", timestamp, author \= "CallSheetComposer" etc.) and relates it to the previous commit in the chain (usually the tip of the main branch) ￼ ￼. All Actions performed during the generation are linked to this commit (see 6.2 below), including the weather API call and the document generation step. The commit also records the exact inputs used: e.g., the specific version IDs of each Scene, the timestamp of the schedule data, the template version, etc., by storing hashes or references. Our design is that given the commit and those recorded inputs, the call sheet could be regenerated exactly – this determinism is important for reproducibility and debugging. Although not fully implemented yet, we envision storing a JSON blob in the commit or an external artifact that captures all input entity IDs and their checksums/versions. This ensures if someone later questions “Why did the call sheet show Character X on that day?”, we can trace it to the state of the graph at generation time. GAP: The actual Composer agents (call sheet, budget, etc.) are still being built out. The script breakdown pipeline (for parsing a screenplay into scenes, etc.) is functional and serves as a model ￼ ￼, but the call sheet generator logic exists only in design documentation. FIX: Implement call sheet generation as a LangGraph workflow graph. This could reuse some of the script analysis components for data gathering. We will likely create a CallSheetGraph with nodes: data collector (queries Neo4j for ShootDay info), validator (ensures prerequisites), weather fetcher (calls API), formatter (calls LLM or fills template), and saver (writes file and creates commit). The LangGraph platform supports constructing such multi-step graphs with both code and LLM steps ￼. We will also add tests with known inputs to verify that given a frozen graph state, the generated PDF matches expected outputs (deterministic content).

#### Compliance/Finance Agent

Role & Responsibilities: The Compliance/Finance agent continuously monitors the Ops ontology in the graph to ensure business rules and regulations are being followed. This includes union labor rules, budget limits, insurance requirements, and so on. For example, one task of this agent is to verify that every crew member’s timesheet complies with union rules (such as overtime pay, meal penalties, maximum work hours). Another is to ensure that if a scene involves a stunt or special hazard, the necessary insurance documents are in place. The agent essentially acts as an automated auditor, flagging any discrepancies or omissions so they can be corrected before they become costly mistakes.

Implementation Approach: As data changes in the Ops ontology (which might be stored partly in Neo4j and partly in relational tables), the Compliance agent will run checks. Currently, much of the needed data (like timesheets, pay rates, etc.) is not yet populated in our system – this is a forward-looking component. We do have a concept of ComplianceRule nodes planned to encode rules (e.g. “Overtime pay rate for crew role X after 12 hours must be 1.5x”) ￼, but these are not implemented in the DB or graph (marked as GAP). FIX: We will introduce a set of :ComplianceRule nodes or a config file that the agent can reference. Each rule will have logic that maps to a Cypher query or a Python check. For instance, a rule for crew pay might correspond to a query like: “MATCH (t:Timesheet)-\[:FOR\_CREW\]-\>(crew)-\[:HAS\_ROLE\]-\>(role) WHERE t.hours \> role.standard\_hours AND t.rate \< role.overtime\_rate RETURN crew,t” – any result indicates a potential underpayment. The agent would iterate through such rules periodically (or subscribe to events like “timesheet submitted”) and perform the queries. If a violation is found, the agent creates a :Violation node in Neo4j describing the issue, and links it to the relevant entities: e.g. (:Violation {type:"UnionCompliance", rule:"OvertimePay"})-\[:INVOLVES\]-\>(that Timesheet node) and also link to the Crew or Project as needed. It would then alert the team, possibly by inserting a notification in an admin\_alerts table or sending an email. In our schema, we have an admin\_alerts table for system alerts ￼ which could be leveraged – the agent can create an entry there via a Postgres insert (the Orchestrator would then surface it in the UI). Another example: for budget monitoring, the agent can sum up all expenses linked to a production (e.g. via (:PurchaseOrder) or (:Expense) nodes) and compare against a budget cap. If the total exceeds 90% of budget, it might raise a warning. Insurance checks: if a ShootDay node has a property stunts=true or a relationship indicating a stunt scene, the agent will ensure there is at least one InsuranceDoc file linked to that day (perhaps via a relationship or a naming convention in File ontology). If not found, that’s a violation – it would create a Violation node like :Violation {type:"MissingInsurance", date: ...} linked to the ShootDay. All such violations can be viewed in the graph or via queries, providing a dynamic “checklist” of compliance issues.

Automation and Resolution: The Compliance agent could also attempt auto-resolution. For instance, if it finds a missing insurance document, and if a likely candidate file exists in the File ontology (maybe someone uploaded a file named “InsuranceCert.pdf” but didn’t link it), the agent could suggest linking that file and even do so automatically if confidence is high. However, any automated fix would be done as a separate commit by the agent (with proper provenance logged). Most often, this agent will just flag issues. Its actions are logged with tool names like "compliance.check.rateCard" or "compliance.check.insurance" and include references to the data checked.

Current Status: Much of this is conceptual at the moment (GAP). We do have placeholders in the schema for crew rates and roles (e.g. a crew table and possibly roles), but no explicit union rules. We plan to populate a reference dataset for union rules (e.g. SAG, DGA rate cards) either in a database table or as JSON in the code. The Compliance agent will be implemented as a scheduled job (perhaps running every night or triggered by certain events like “timesheet submitted” in Supabase). In code, it could live in the Orchestrator service or a separate ops\_worker. The Neo4j graph makes it easy to traverse connected data (crew \-\> timesheet \-\> shoot day \-\> etc.), so many checks can be done with single Cypher queries. Once implemented, this agent should significantly reduce human error by catching issues early. Every violation it logs will also be part of the provenance chain, so months later one can ask “why did we adjust CrewMember A’s pay?” and see the violation node and resolution commit that explained it.

#### Scheduler Agent

Role & Responsibilities: The Scheduler agent’s job is to react to changes in the scheduling domain (Scenes, ShootDays, crew availability) and keep the related parts of the plan in sync. For example, if the shooting schedule is updated – say Scene 5, originally planned for Aug 9, is moved to Aug 12 – this agent will notice and propagate the effects of that change. It might update call times for actors and crew on those days, trigger regeneration of the call sheets for the affected days, and send notifications about the change. Essentially, it maintains consistency between the Content ontology (what scenes are shot when, with whom) and the operational logistics.

Triggers: This agent can be triggered by various events: a direct user edit to a scheduling entry, an import of a new schedule file, or even an automated optimization. In our system, schedule data might enter as a structured spreadsheet that gets ingested (via File Steward) and converted into :ShootDay nodes with :COVERS\_SCENE relationships to Scene nodes. If that file is replaced or a Scene’s date is changed, a new commit will record that in the graph. The Scheduler agent monitors for such commits or listens to an event stream of schedule changes (this could be a Pub/Sub message or just polling the graph for recent changes).

Actions: Upon detecting a scheduling change, the agent will perform several updates **via EdgeFacts**. Taking the Scene 5 move example: **CRITICAL - EdgeFact Implementation:** When moving a scene between shoot days, the **Scheduler Agent** must create a **closing** EdgeFact for the old `(day,scene)` pair and a **new** EdgeFact for the new pair; the convenience `[:COVERS_SCENE]` relationship will follow automatically. This ensures full temporal tracking of schedule changes. The agent creates EdgeFacts with `type='COVERS_SCENE'`, properly closing the old EdgeFact with `valid_to = now()` and creating a new one with `valid_from = now()`. Trigger downstream recomputes from commit hooks.

The agent finds that Scene 5's EdgeFact linking to ShootDay(Aug9) needs to be closed and a new EdgeFact created linking to ShootDay(Aug12). It then looks at all crew and cast associated with Scene 5 (e.g. via (:Character)-\[:FEATURED\_IN\]->(Scene5) for cast, and crew via department assignments) and updates their call sheet entries. If call times were pre-set for Aug9, those need to move to Aug12. Concretely, if our graph models call times explicitly (perhaps as properties on the relationship between Crew and ShootDay, or via a separate CallTime node), the agent will adjust those via EdgeFacts as well. It might also check for conflicts (if an actor was also scheduled elsewhere on Aug12, that's a conflict to flag). After internal adjustments, the agent will prompt the Call Sheet Composer to regenerate the call sheets for Aug9 (which lost a scene, so that day's call sheet changes) and Aug12 (new scene added). This could be done by creating task entries or simply by calling the Composer agent's routine for those dates. The agent might also send out notifications: e.g. drop a message in the crew\_inbox table for each affected crew member or push an update to a calendar integration. Our system has a crew\_inbox and task system (which we suspect is used for agent-human interactions) ￼ ￼ – the Scheduler could create an entry like "Your call time changed from 7:00 to 9:00 on Aug 12".

State & Implementation: The Scheduler agent can run as part of the LangGraph orchestration as well, since it may utilize an LLM to evaluate complex rescheduling issues (e.g. if multiple scenes shift, maybe ask “what’s the optimal new order?”). For simpler deterministic updates, plain code will suffice. This agent is currently not implemented (GAP); schedule consistency is maintained manually. FIX: We plan to implement an event-driven handler in the Sync Worker or Orchestrator that triggers on changes to ShootDay or schedule-related tables. Possibly, a database trigger on the schedule table (if one exists in Supabase) could enqueue a “schedule\_changed” event. The Scheduler agent process would consume that, run a series of Cypher queries to identify impacted entities, and then perform updates either via Cypher or by enqueuing further tasks (like telling the Composer agent to regenerate documents). Each such cascade will be done carefully to avoid infinite loops (e.g., the Composer writing a new file will itself generate events; we use commit metadata to distinguish an automated regeneration versus a user-initiated change to avoid re-triggering continuously). All changes by Scheduler are of course recorded as a commit with appropriate provenance.

#### Other Domain-Specific Agents

The architecture is designed to be extensible with additional agents as new needs arise. Some ideas include: a Risk Assessment Agent that watches for any changes which might introduce safety or budget risks (e.g. a script change adding a stunt might cause it to warn “Stunt added – ensure stunt coordinator and safety measures are scheduled”); an Insights Agent that can answer ad-hoc natural language questions about the production by translating them into Cypher queries (essentially a chat-based interface to the graph); or a Version Cleanup Agent that archives or prunes old branches of the graph once a production phase is over. These would each have access only to their slice of the graph and specific tools. For instance, an Insights Agent might use a tool that converts English questions to Cypher (fine-tuned or prompt-engineered for our schema). Indeed, our LangGraph Orchestrator has a multi-worker AI system that could serve this purpose – e.g., a “query worker” and a “reasoning worker” collaborate to interpret questions and fetch answers ￼. Integrating such an agent would involve adding new nodes in the LangGraph execution graph that utilize those workers and possibly the vector search (if we support semantic QA from file contents). The architecture readily supports plugging these in, as each agent simply creates new commits with its actions, and can be audited the same way. As with all agents, these would be configured with allowed tools (e.g. the Insights Agent might be allowed read-only Cypher queries and GPT-4, but not allowed to modify data without human approval). Our design principle is that agents should be narrow in scope, operating like expert assistants, and their “paper trail” in the graph allows us to trust (and if needed, rollback) their contributions.

Each agent runs with a specific identity and toolset, and we log each tool invocation. The LangGraph framework we use provides an underlying engine to define these agents as compositions of nodes (functions or LLM calls) in a directed graph of steps ￼ ￼. This lets us orchestrate complex behaviors (like the script breakdown or call sheet generation) with branching, parallelism, and retries in a high-level way. In runtime, agents either operate continuously (event-driven daemons like the Sync/File Steward agent) or are invoked on-demand via the Orchestrator (e.g. a user clicks “Generate Call Sheet” which calls the Composer agent). The next subsection explains how we capture a complete audit trail of everything these agents do.

### 6.2 Provenance of Actions (Audit for AI)

To maintain trust and transparency, every action performed by any agent is meticulously logged as part of the graph’s provenance layer. We model this with two main node types in Neo4j: :Commit and :Action. A Commit represents a high-level operation or transaction (analogous to a Git commit) that may encompass multiple low-level actions. Each Commit has metadata like an ID, timestamp, author (which can be a user ID for human actions or an agent identifier for automated actions), and an optional message/description ￼ ￼. Commits are linked in a chain to record history – each commit node has a :PARENT relationship to one or more previous commits (one for normal sequential commits, or two for a merge in branching scenarios) ￼ ￼. An Action, on the other hand, represents a single atomic operation or tool invocation that occurred as part of a commit. We attach the following key properties to each :Action node in the graph (largely reflecting what’s described in the design doc):

	•	tool – A short identifier of which tool or function was used. For a code function, this might be a namespace like "ingest.pdf.parse"; for an LLM API call, "llm.call.openai"; for a database operation, "neo4j.merge"; for an external API, e.g. "weather.fetch" ￼. This gives a quick view of what kind of action it was.

	•	inputs – A structured summary or hash of the inputs given to that tool. This could be a JSON with parameters (for API calls), a prompt string (for LLM, though if it’s large or sensitive we might store a hash or pointer instead), or just an ID of an internal object. We avoid storing full raw data in this property if it’s big or sensitive; instead we might store a reference (e.g. an S3 key where the prompt is saved encrypted) – this is implied by our design for secure input storage ￼. Still, we want enough info to later understand what the agent was acting on.

	•	outputs – Similar to inputs, a summary or reference to the results of the action. For deterministic functions, this could be small (e.g. "success": true or the new node’s ID). For larger outputs (like an LLM’s entire response text or a generated file path), it may be a truncated summary or a hash to lookup the real data. For example, after a file generation, the output might be {fileId: <UUID>, fileHash: <SHA256>} to identify the new file ￼.

	•	status – The result status code or metadata (success/failure, error message if any, execution duration, cost in tokens, etc.) ￼. This helps filter actions (e.g. find all failed actions) and audit performance/cost. For LLM calls, we record tokens used and model name here via the tooling integration.

All these fields together fully describe each step an agent took. In the Neo4j model, each :Action node is related to the rest of the graph in two ways. First, it is linked to its encompassing Commit: we create a relationship (:Commit)-[:INCLUDES]->(:Action) for every action in that commit ￼ ￼. This lets us fetch the list of actions given a commit (preserving their order if needed by an order property or by the inherent creation order). Second, **every Action MUST be linked with TOUCHED edges to BOTH old and new versions/facts** for complete lineage tracking. The (:Action)-[:TOUCHED {mode: 'read'|'write'}]->(:EntityVersion|:EdgeFact) relationships provide precise before-and-after state tracking. For reads, we point to the version/fact whose data was accessed; for writes, we point to BOTH the previous version/fact (if any) with mode='read' AND the newly created version/fact with mode='write'. **Action creation is part of the atomic Provenance Write Path transaction** - Actions are not created separately but as an integral part of the single write transaction that also creates commits, versions entities, versions edges, and maintains all TOUCHED relationships atomically. This ensures complete consistency and eliminates any possibility of orphaned actions or missing lineage links.

Example: Suppose our Call Sheet Composer agent is running, and it calls the weather API and then generates a PDF. In a single commit (say commit ID C123), we would have: one Action node for the weather fetch (tool = "weather.api", inputs = {"location":"LA","date":"2025-08-09"}, outputs = {"forecast":"Cloudy 75F"}, status = "success"), and another Action for the document generation (tool = "callsheet.generate", inputs = {"scenes":[...], "weather":"Cloudy 75F", ...}, outputs = {"fileId": "...", "filePath": "..."}, status="success"). These Actions get linked to commit C123 via C123-[:INCLUDES]->(Action1) and C123-[:INCLUDES]->(Action2). Additionally, suppose Action1 (weather.api) read the ShootDay node for Aug 9 to know the location; we create Action1-[:TOUCHED]->(ShootDay_Aug9) ￼. It also effectively “wrote” a weather property on that node (if we store the forecast in the graph), so that same relationship signifies it touched that node’s state. For Action2 (callsheet.generate), it read a bunch of nodes – all the Scenes scheduled that day, the related Crew and Cast, etc. – and it wrote a new File node. So we would add :TOUCHED from that Action to each Scene, Crew, Location node that provided input and one to the new File node it created ￼. In Cypher pseudo-code, after commit C123 is created, we do something like:

UNWIND $actions AS act {

   CREATE (a:Action {tool: act.tool, inputs: act.inputs, outputs: act.outputs, status: act.status}),

   MERGE (commit:C123)-\[:INCLUDES\]-\>(a)

   FOREACH (entId IN act.touched | 

      MERGE (e) WHERE id(e) \= entId 

      MERGE (a)-\[:TOUCHED\]-\>(e)

   )

}

This is a simplified representation of what our code would do (the actual implementation would use parameter maps and two-phase creation to get e nodes by id) ￼ ￼. The effect is that anyone inspecting, say, the File node for CallSheet 2025-08-09.pdf in the graph can traverse (:File)\<-\[:TOUCHED\]-(:Action)\<-\[:INCLUDES\]-(:Commit) and see exactly how and when it was generated and by which agent ￼ ￼. They could further traverse out from that Action to see all the input nodes that fed into it (via the other TOUCHED relationships) – listing precisely which scene versions, which weather data, etc., were referenced. This addresses the “black box” problem often associated with AI: instead of a mystery how an output was produced, we have a transparent ledger.

We use this provenance data to enable queries like “Who last updated this prop’s info and when?” or “What tool was used to extract the cast list from script file X?” ￼. For the former, one would find the Prop node, look at the latest :Commit that affected it (via (:Action)-\[:TOUCHED\]-\>(Prop)), and see the commit’s author and timestamp – perhaps it shows author="script\_breakdown\_agent" at 2025-07-01, meaning the screenplay ingest agent set that prop info on July 1\. For the latter question, find the File node for the script, see which Action created the Cast entities or relationships from it (likely an Action with tool "llm.extractCharacters" or "parse.pdf"), and you have the answer – including the exact tool name that was used to parse it.

Audit and Reproducibility: Every :Action can also store performance metrics (e.g. duration, token count) which we include in the status or as separate properties. This allows us to audit cost (sum of tokens used in all llm.call.openai actions in a commit, for instance) and identify bottlenecks. Moreover, by capturing input hashes, we can later rerun an Action if needed. In fact, one could imagine a “replay” feature: take a commit, and automatically re-invoke each action in it on the recorded inputs to verify the outputs match – a powerful test for deterministic behavior or regression catching. Our design leans toward determinism: given the same inputs, agents should produce the same outputs (especially for critical documents). Where AI randomness is involved, we constrain it (or record the random seed or LLM temperature) to ensure reproducibility ￼. We also incorporate approval steps for non-deterministic suggestions (e.g. Ontology Curator might require a human commit for actual schema changes).

Currently, the Provenance ontology is in design – the sync/ingest pipeline does not yet create Commit and Action nodes for each change (this is noted as a GAP in the design) ￼ ￼. For example, right now when a file is ingested, the File node is upserted but we don’t automatically create a commit node describing “File X ingested and classified as Y” with actions. FIX: We plan to extend the Sync Worker so that for each batch of events it processes, it will create a new Commit node (author \= "FileStewardAgent", message like “Ingested 3 files”) and attach Action nodes for each low-level operation it did ￼ ￼. In practice, this means wrapping the Neo4j upsert queries in extra queries that create those provenance nodes. We have to be careful to capture the Neo4j internal identifiers of nodes that were touched (as seen in the pseudo-cypher above, using id(e) or a similar mechanism) so we can connect Action \-\> domain nodes. We may use Neo4j’s transaction workflow: do the upserts, collect the touched node IDs in variables, then create the commit/actions in the same transaction. Another adjustment is needed in our data model: ensuring every domain node (File, Scene, Crew, etc.) has a stable internal ID or we use Neo4j’s elementId() since id(e) (the default) can recycle after deletion. Using elementId() might be preferable for long-term provenance links.

Finally, we maintain the branch and merge structure of the commit graph (to be detailed in Section 8). In brief, the main production data lives on the “main” branch (sequence of commits). If someone conducts a what-if experiment (say, trying an alternate schedule), the system can branch the graph, the agents can operate on that branch (e.g. generate call sheets on the alternate schedule, producing commits on that branch), and later we can either merge or discard that branch ￼. The Commit nodes have an attribute for branch (or we have separate branch nodes with relationships). Merging branches would result in a commit with two parents. The provenance model we’ve chosen aligns with this by not tying commits to a single linear history but allowing DAG structure. The Action logs remain the same on a branch – an agent doesn’t need to know, it just writes its commit and actions in whatever branch context it’s running. This gives us full version control for the knowledge graph, with the ability to diff commits, roll back a commit (by reverting the changes via a new commit), or inspect alternative futures in parallel. All of it is achieved by the combination of the agent system performing controlled changes and the provenance system recording those changes in graph form.

In summary, the Agent System (LangGraph) is the intelligent automation layer that acts on the production knowledge graph, while the Provenance subsystem ensures every act is transparent and traceable. This design brings accountability to AI-driven operations: we gain the efficiencies of automation and AI assistance, but without hand-wavy “the system decided this” – instead, every decision is a first-class data object we can query, audit, debug, and learn from ￼. This closes the loop in our platform: as agents continuously enrich and update the graph (under human oversight), the graph in turn provides the single source of truth that agents (and humans) rely on, all with an auditable memory of how it’s been built.

**TELEMETRY:** The agent system emits comprehensive metrics for observability and SLO monitoring (detailed in Section 7): `agent_job_duration_seconds{agent_type, org_id, status}` tracks execution times for each agent workflow, `agent_job_queue_depth{agent_type, org_id}` monitors pending jobs in agent queues, `agent_job_success_rate{agent_type, org_id}` measures successful completion rates, and `agent_error_total{agent_type, org_id, error_code}` counts execution failures by type. These metrics enable monitoring against SLO targets of 95% job success rate, 90% completion within 60 seconds, and queue depths below 100 pending jobs during normal operation.

---