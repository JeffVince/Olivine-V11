# AI Agent Console (Chat & Logs)

* [ ] **AI Agent Console (Chat & Logs):** An interface for users to interact with the platform's AI agents directly through natural language or view agent activities.

  * [ ] **Chat Interface:** Provide a chat-style console where the user can ask questions or give commands to an AI assistant agent. The assistant can answer questions about the project (e.g. "Which files are missing required metadata?") or perform tasks on request (subject to approval workflows for actions).

    * [ ] Include a text input box with support for multi-line queries and a send button (and pressing Enter to send).
    * [ ] Display the conversation history above, differentiating user queries and AI responses (with styling or labels). Use streaming response display so the answer appears token-by-token or line-by-line for quicker feedback.
    * [ ] Allow the AI to reference project data: ensure context (like current project, selected file) is included so the assistant can respond usefully (e.g. if user asks about a specific file, and it's selected or mentioned by name). Possibly integrate with the command palette or inspector (e.g. "Open in Agent Console" for a file to ask questions about it).
    * [ ] Handle follow-up questions by maintaining conversation state (the Orchestrator's chat endpoint with session ID). Provide a way to reset the session if needed (new conversation).
  * [ ] **Agent Responses & Tools:** When the AI performs an action or needs to show a result beyond text, handle it in the UI. For instance, if the assistant triggers a file search or a task, show the outcome (like a list of files or a confirmation that a task has been queued). If a request will produce a long-running result (like "Audit the whole project"), the console should inform the user that it's working and perhaps advise them to check back or see suggestions once ready.
  * [ ] **Agent Run Feedback:** If the user initiates a complex agent task via chat (like "Classify all new files" or "Generate tomorrow's call sheet"), provide feedback on progress. This could include intermediate messages or status updates in the chat (e.g. "File Steward agent is checking 10 files…") and a final summary or link (like "Found 3 issues; see the Approvals page for details"). Leverage streaming or real-time messages so the user isn't left waiting without indication.
  * [ ] **Contextual Prompts:** Offer quick-insert prompts or buttons for common queries (especially for less technical users). For example, buttons like "Ask 'Any naming issues?'" or "Generate daily summary" that populate the input for the user. This makes the console more approachable.
  * [ ] **Logs / Chain-of-Thought (Advanced):** (Optional/Phase 2) Provide an expandable panel or toggle to view detailed agent logs or reasoning steps for the last query. This could be useful for transparency or debugging when an agent's answer seems off. For example, show a step-by-step of which tools the agent used and any intermediate results. This should be hidden by default to avoid confusion, but power users or developers can inspect it.
  * [ ] **Error Handling in Chat:** If the AI fails to answer (error from backend) or times out, display a friendly error message in the chat (e.g. "The assistant could not complete that request. Please try again later."). If a specific error is known (like no internet for a tool, or auth failure), mention it so the user has context (e.g. "Unable to fetch weather info – integration token may have expired"). Allow the user to retry easily.
